{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfc0WCPTGX06HC9ARBEhT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawnteh1711/tensorflow/blob/master/TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "glaqw-wG-BHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSYhZh8U9Bd3",
        "outputId": "a1b6a575-526d-454d-f454-b6724e0642d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "fvNiqZis9vvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess Data"
      ],
      "metadata": {
        "id": "7pLSbpDRErj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "X, y = (data.data, data.target)\n",
        "\n",
        "# print(data)\n",
        "# print(\"feature: \", X)\n",
        "# print(\"target: \", y)\n",
        "feature_names = data.feature_names\n",
        "# print(\"feature_names: \", feature_names)\n",
        "target_names = data.target_names\n",
        "# print(\"target_names: \", target_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# print(\"X_train: \", X_train)\n",
        "# print(\"X_test: \", X_test)\n",
        "# print(\"y_train: \", y_train)\n",
        "# print(\"y_test: \", y_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "# print(\"X_train: \", X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQhPnGoQ-LJO",
        "outputId": "39d6f18e-f1af-4b12-a97f-0b28ba765ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test:  [[1.247e+01 1.860e+01 8.109e+01 ... 1.015e-01 3.014e-01 8.750e-02]\n",
            " [1.894e+01 2.131e+01 1.236e+02 ... 1.789e-01 2.551e-01 6.589e-02]\n",
            " [1.546e+01 1.948e+01 1.017e+02 ... 1.514e-01 2.837e-01 8.019e-02]\n",
            " ...\n",
            " [1.152e+01 1.493e+01 7.387e+01 ... 9.608e-02 2.664e-01 7.809e-02]\n",
            " [1.422e+01 2.785e+01 9.255e+01 ... 8.219e-02 1.890e-01 7.796e-02]\n",
            " [2.073e+01 3.112e+01 1.357e+02 ... 1.659e-01 2.868e-01 8.218e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a TensorFlow Model"
      ],
      "metadata": {
        "id": "NiwGu4lkI48c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"X_train.shape[1]: \", X_train.shape[1])\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# help(model.compile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hejT8l8P_jYM",
        "outputId": "f7147015-bd66-4a83-e23d-4f63050565a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method compile in module keras.src.engine.training:\n",
            "\n",
            "compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, pss_evaluation_shards=0, **kwargs) method of keras.src.engine.sequential.Sequential instance\n",
            "    Configures the model for training.\n",
            "    \n",
            "    Example:\n",
            "    \n",
            "    ```python\n",
            "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
            "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
            "                  metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
            "                           tf.keras.metrics.FalseNegatives()])\n",
            "    ```\n",
            "    \n",
            "    Args:\n",
            "        optimizer: String (name of optimizer) or optimizer instance. See\n",
            "          `tf.keras.optimizers`.\n",
            "        loss: Loss function. May be a string (name of loss function), or\n",
            "          a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
            "          function is any callable with the signature `loss = fn(y_true,\n",
            "          y_pred)`, where `y_true` are the ground truth values, and\n",
            "          `y_pred` are the model's predictions.\n",
            "          `y_true` should have shape\n",
            "          `(batch_size, d0, .. dN)` (except in the case of\n",
            "          sparse loss functions such as\n",
            "          sparse categorical crossentropy which expects integer arrays of\n",
            "          shape `(batch_size, d0, .. dN-1)`).\n",
            "          `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            "          The loss function should return a float tensor.\n",
            "          If a custom `Loss` instance is\n",
            "          used and reduction is set to `None`, return value has shape\n",
            "          `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
            "          values; otherwise, it is a scalar. If the model has multiple\n",
            "          outputs, you can use a different loss on each output by passing a\n",
            "          dictionary or a list of losses. The loss value that will be\n",
            "          minimized by the model will then be the sum of all individual\n",
            "          losses, unless `loss_weights` is specified.\n",
            "        metrics: List of metrics to be evaluated by the model during\n",
            "          training and testing. Each of this can be a string (name of a\n",
            "          built-in function), function or a `tf.keras.metrics.Metric`\n",
            "          instance. See `tf.keras.metrics`. Typically you will use\n",
            "          `metrics=['accuracy']`.\n",
            "          A function is any callable with the signature `result = fn(y_true,\n",
            "          y_pred)`. To specify different metrics for different outputs of a\n",
            "          multi-output model, you could also pass a dictionary, such as\n",
            "          `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
            "          You can also pass a list to specify a metric or a list of metrics\n",
            "          for each output, such as\n",
            "          `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            "          or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            "          strings 'accuracy' or 'acc', we convert this to one of\n",
            "          `tf.keras.metrics.BinaryAccuracy`,\n",
            "          `tf.keras.metrics.CategoricalAccuracy`,\n",
            "          `tf.keras.metrics.SparseCategoricalAccuracy` based on the shapes\n",
            "          of the targets and of the model output. We do a similar\n",
            "          conversion for the strings 'crossentropy' and 'ce' as well.\n",
            "          The metrics passed here are evaluated without sample weighting; if\n",
            "          you would like sample weighting to apply, you can specify your\n",
            "          metrics via the `weighted_metrics` argument instead.\n",
            "        loss_weights: Optional list or dictionary specifying scalar\n",
            "          coefficients (Python floats) to weight the loss contributions of\n",
            "          different model outputs. The loss value that will be minimized by\n",
            "          the model will then be the *weighted sum* of all individual\n",
            "          losses, weighted by the `loss_weights` coefficients.  If a list,\n",
            "          it is expected to have a 1:1 mapping to the model's outputs. If a\n",
            "          dict, it is expected to map output names (strings) to scalar\n",
            "          coefficients.\n",
            "        weighted_metrics: List of metrics to be evaluated and weighted by\n",
            "          `sample_weight` or `class_weight` during training and testing.\n",
            "        run_eagerly: Bool. If `True`, this `Model`'s logic will not be\n",
            "          wrapped in a `tf.function`. Recommended to leave this as `None`\n",
            "          unless your `Model` cannot be run inside a `tf.function`.\n",
            "          `run_eagerly=True` is not supported when using\n",
            "          `tf.distribute.experimental.ParameterServerStrategy`. Defaults to\n",
            "           `False`.\n",
            "        steps_per_execution: Int or `'auto'`. The number of batches to\n",
            "          run during each `tf.function` call. If set to \"auto\", keras will\n",
            "          automatically tune `steps_per_execution` during runtime. Running\n",
            "          multiple batches inside a single `tf.function` call can greatly\n",
            "          improve performance on TPUs, when used with distributed strategies\n",
            "          such as `ParameterServerStrategy`, or with small models with a\n",
            "          large Python overhead. At most, one full epoch will be run each\n",
            "          execution. If a number larger than the size of the epoch is\n",
            "          passed, the execution will be truncated to the size of the epoch.\n",
            "          Note that if `steps_per_execution` is set to `N`,\n",
            "          `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
            "          only be called every `N` batches (i.e. before/after each\n",
            "          `tf.function` execution). Defaults to `1`.\n",
            "        jit_compile: If `True`, compile the model training step with XLA.\n",
            "          [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
            "          for machine learning.\n",
            "          `jit_compile` is not enabled for by default.\n",
            "          Note that `jit_compile=True`\n",
            "          may not necessarily work for all models.\n",
            "          For more information on supported operations please refer to the\n",
            "          [XLA documentation](https://www.tensorflow.org/xla).\n",
            "          Also refer to\n",
            "          [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
            "          for more details.\n",
            "        pss_evaluation_shards: Integer or 'auto'. Used for\n",
            "          `tf.distribute.ParameterServerStrategy` training only. This arg\n",
            "          sets the number of shards to split the dataset into, to enable an\n",
            "          exact visitation guarantee for evaluation, meaning the model will\n",
            "          be applied to each dataset element exactly once, even if workers\n",
            "          fail. The dataset must be sharded to ensure separate workers do\n",
            "          not process the same data. The number of shards should be at least\n",
            "          the number of workers for good performance. A value of 'auto'\n",
            "          turns on exact evaluation and uses a heuristic for the number of\n",
            "          shards based on the number of workers. 0, meaning no\n",
            "          visitation guarantee is provided. NOTE: Custom implementations of\n",
            "          `Model.test_step` will be ignored when doing exact evaluation.\n",
            "          Defaults to `0`.\n",
            "        **kwargs: Arguments supported for backwards compatibility only.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "7hd253CIMRmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ4yK0NxK2N3",
        "outputId": "72b80554-b020-4f76-cdc2-54dc87342fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 2s 24ms/step - loss: 0.4800 - accuracy: 0.8297 - val_loss: 0.3613 - val_accuracy: 0.8901\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.9231 - val_loss: 0.2587 - val_accuracy: 0.9451\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2227 - accuracy: 0.9451 - val_loss: 0.2084 - val_accuracy: 0.9451\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9478 - val_loss: 0.1814 - val_accuracy: 0.9451\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 0.9533 - val_loss: 0.1646 - val_accuracy: 0.9451\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9588 - val_loss: 0.1530 - val_accuracy: 0.9451\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1219 - accuracy: 0.9670 - val_loss: 0.1440 - val_accuracy: 0.9451\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9725 - val_loss: 0.1366 - val_accuracy: 0.9451\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9753 - val_loss: 0.1311 - val_accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 0.9780 - val_loss: 0.1263 - val_accuracy: 0.9670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d2db90a9270>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model"
      ],
      "metadata": {
        "id": "f1vkFlI1QCPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqSZfEq9QBG2",
        "outputId": "310230d8-9497-4ca1-db1f-9ace95f0d485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9825\n",
            "Test Loss: 0.07886411249637604, Test Accuracy: 0.9824561476707458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions"
      ],
      "metadata": {
        "id": "Dca1FYh8QZNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCkN8iDqQbbi",
        "outputId": "dd6c51a9-9383-40f6-ec4b-0f33880d57d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "[[8.20825458e-01]\n",
            " [3.20909638e-03]\n",
            " [4.72218990e-02]\n",
            " [9.64369476e-01]\n",
            " [9.90518987e-01]\n",
            " [2.50552466e-06]\n",
            " [3.42747990e-05]\n",
            " [9.94342566e-02]\n",
            " [4.84712481e-01]\n",
            " [9.85735118e-01]\n",
            " [9.23135340e-01]\n",
            " [7.99553245e-02]\n",
            " [9.63280737e-01]\n",
            " [1.85644850e-01]\n",
            " [9.93080199e-01]\n",
            " [5.08907018e-03]\n",
            " [9.81377125e-01]\n",
            " [9.98025537e-01]\n",
            " [9.99681473e-01]\n",
            " [6.31794508e-04]\n",
            " [7.55842805e-01]\n",
            " [9.66998458e-01]\n",
            " [3.02332792e-05]\n",
            " [9.97666299e-01]\n",
            " [9.79325175e-01]\n",
            " [9.71706867e-01]\n",
            " [9.84033346e-01]\n",
            " [9.58969355e-01]\n",
            " [9.71937656e-01]\n",
            " [7.90643157e-04]\n",
            " [9.45173740e-01]\n",
            " [9.95831251e-01]\n",
            " [9.71128821e-01]\n",
            " [9.80114222e-01]\n",
            " [9.94415998e-01]\n",
            " [9.86805320e-01]\n",
            " [2.68486589e-01]\n",
            " [9.74548638e-01]\n",
            " [6.60349289e-03]\n",
            " [8.09021950e-01]\n",
            " [9.88295197e-01]\n",
            " [4.46174331e-02]\n",
            " [9.71320987e-01]\n",
            " [9.90192413e-01]\n",
            " [9.08904791e-01]\n",
            " [9.73621428e-01]\n",
            " [9.94625688e-01]\n",
            " [9.92217541e-01]\n",
            " [9.35350299e-01]\n",
            " [9.73772168e-01]\n",
            " [9.55911446e-03]\n",
            " [2.97960738e-04]\n",
            " [5.83565056e-01]\n",
            " [8.44956577e-01]\n",
            " [9.85075235e-01]\n",
            " [9.81091142e-01]\n",
            " [9.84437287e-01]\n",
            " [1.04968012e-06]\n",
            " [2.83267021e-01]\n",
            " [9.95974600e-01]\n",
            " [9.57378209e-01]\n",
            " [4.24952275e-04]\n",
            " [1.07396874e-04]\n",
            " [9.14546072e-01]\n",
            " [9.93426263e-01]\n",
            " [8.93954933e-01]\n",
            " [3.53228278e-03]\n",
            " [2.10838898e-05]\n",
            " [9.91153121e-01]\n",
            " [9.15629089e-01]\n",
            " [1.16526969e-01]\n",
            " [3.69830839e-02]\n",
            " [9.75487232e-01]\n",
            " [3.63832526e-02]\n",
            " [9.97988641e-01]\n",
            " [9.48845565e-01]\n",
            " [9.32120681e-01]\n",
            " [4.64326918e-01]\n",
            " [9.98236835e-01]\n",
            " [9.27478850e-01]\n",
            " [3.08405813e-02]\n",
            " [9.98038828e-01]\n",
            " [3.98647249e-01]\n",
            " [1.74769506e-04]\n",
            " [4.04174477e-02]\n",
            " [1.10521233e-02]\n",
            " [8.20470974e-03]\n",
            " [1.19874384e-02]\n",
            " [9.78891551e-01]\n",
            " [9.63660359e-01]\n",
            " [9.66674149e-01]\n",
            " [7.82108903e-01]\n",
            " [7.95293689e-01]\n",
            " [9.92820561e-01]\n",
            " [9.94725466e-01]\n",
            " [9.95937645e-01]\n",
            " [1.20168575e-03]\n",
            " [1.51395088e-03]\n",
            " [9.98056233e-01]\n",
            " [1.90952551e-02]\n",
            " [5.99607602e-02]\n",
            " [9.99609590e-01]\n",
            " [2.42474559e-03]\n",
            " [1.04076760e-02]\n",
            " [9.62982118e-01]\n",
            " [9.09410536e-01]\n",
            " [9.47525740e-01]\n",
            " [1.77740076e-05]\n",
            " [8.18830669e-01]\n",
            " [9.39932168e-01]\n",
            " [6.06658757e-02]\n",
            " [9.80394959e-01]\n",
            " [6.16053641e-01]\n",
            " [2.65880726e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YIh_ydwnP8oJ"
      }
    }
  ]
}